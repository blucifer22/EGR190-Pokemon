---
title: "Pokemom Data Analysis"
output: github_document
author: Yi Chen
date: Oct 24, 2019
---

```{r data_import, include=FALSE}

library(tidyverse)
library(broom)
library(dplyr)
library(lubridate)
library(stringi)


data <- read.csv("data.csv")



# Remove empty rows
data <- data %>%
  select(1:4)

names(data) <- c("fileName", "name", "type1", "type2")


```


## A Glance at the Dataset

Below is our dataset, where the `fileName` columns are strings that correspond to the file names of the images, the `name` column contains the name of each Pokemon, and the `type1` and `type2` column provide their classifications.

```{r basic}
data %>%
  head()

count1 <- data %>%
  count(type1) %>%
  arrange(desc(n))
count1
```

We can see above that there is a rather large variation in the number of images we have of each Pokemon type, we expect this to have some negative effects on our model's ability to scale. 

Some Pokemons have secondary types: 

```{r type2}
count2 <- data %>%
  count(type2) %>%
  arrange(desc(n)) %>%
  # removing counts for empty strings
  slice(-1)
count2

sum(count1$n)
sum(count2$n)
```

Calculating the sums, we see that the secondary type is missing for many Pokemon types. Therefore, we will be using `type1` to label our training data for the model. 

```{r plot}
count1 %>%
  ggplot(mapping = aes(x = reorder(type1, n), y = n)) +
  geom_col(fill = "dodgerblue") + 
  coord_flip() + 
  labs(x = "Count", y = "Pokemon type", 
       title = "Counts of Pokemon Types") + 
  theme_minimal()


```

